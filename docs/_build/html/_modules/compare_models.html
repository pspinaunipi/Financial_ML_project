
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>compare_models &#8212; Bagging and boosting in financial machine learning 1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/classic.css" />
    
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Bagging and boosting in financial machine learning 1.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">compare_models</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for compare_models</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This is the module we used to make the computations descibed in the chapter about probability.</span>
<span class="sd">At the beginning of the main 3 boolean variables can be set.</span>

<span class="sd">1)COMPUTE_PROB:</span>
<span class="sd">    If set to True a user can set up a pipeline containing a classifier and 5 .csv</span>
<span class="sd">    files will be added in the cartella Proba, containing the classification probability</span>
<span class="sd">    of each object of 5 different test-sets. At each iteration the classifier is trained on a</span>
<span class="sd">    different training set.</span>

<span class="sd">2)COMPUTE_ACC:</span>
<span class="sd">    If set to True computes the accuracy over different probability thresholds</span>

<span class="sd">3)DISTRIBUTION:</span>
<span class="sd">    If set to True an image showing the probability distribution of one of the classifier</span>
<span class="sd">    used in COMPUTE_PROB is returned</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">BaggingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>


<div class="viewcode-block" id="compute_probabilities"><a class="viewcode-back" href="../analyze_results/compare_models.html#compare_models.compute_probabilities">[docs]</a><span class="k">def</span> <span class="nf">compute_probabilities</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pipe</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function trains a classifier and then computes the class probabilities</span>
<span class="sd">    for a test set compose by the last 50 days of the dataset. This function returns a</span>
<span class="sd">    .csv file located in the filepath given by the user</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data: DataFrame</span>
<span class="sd">        The dataset used to fit the model</span>
<span class="sd">    pipe: Pipeline</span>
<span class="sd">        The pipeline for the classifier</span>
<span class="sd">    name: string</span>
<span class="sd">        the name used to save the dataframe containig all the informations about the</span>
<span class="sd">        search</span>

<span class="sd">    Yields</span>
<span class="sd">    ------</span>
<span class="sd">    A csv file, saved in the location indicated by the filepath</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># divide in train and test set leaving a 50 days gap between them</span>
    <span class="n">max_date</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;date&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;date&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">max_date</span><span class="o">-</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;action&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;date&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">max_date</span><span class="o">-</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;action&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># the test set i composed of the last 50 days of trading</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;date&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">max_date</span><span class="o">-</span><span class="mi">50</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;action&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;date&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">max_date</span><span class="o">-</span><span class="mi">50</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;action&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>

    <span class="c1"># fit the model</span>
    <span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># compute probability</span>
    <span class="n">probability1</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># create a dataframe for the probabilities</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;first classifier&#39;</span><span class="p">:</span> <span class="n">probability1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                         <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">y_test</span><span class="p">})</span>

    <span class="c1"># save the dataframe</span>
    <span class="n">prob</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;proba/probabilities_</span><span class="si">{}</span><span class="s1">.csv&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span></div>


<div class="viewcode-block" id="compute_accuracy"><a class="viewcode-back" href="../analyze_results/compare_models.html#compare_models.compute_accuracy">[docs]</a><span class="k">def</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function takes as imput a dataframe created by the function compute_probabilities</span>
<span class="sd">    and then it returns a dataframe containig important informations such as</span>
<span class="sd">    1) The classification accuracy on the label 1</span>
<span class="sd">    2) The ratio of the labels classified as 1</span>
<span class="sd">    3) The name of the classifier</span>
<span class="sd">    4) The probability value</span>
<span class="sd">    5) the function</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filepath: str</span>
<span class="sd">        The filepath of the dataframe</span>
<span class="sd">    vmax: int [0,1000] (default=None)</span>
<span class="sd">        The maximum probability threshold considered. If vmax=None it is chosen automatically</span>
<span class="sd">        as the minumum between the second highest treshold that returns 0 and the tenth highest threshod</span>
<span class="sd">        that returns 1.</span>
<span class="sd">    vmin: int [0,1000] (default=500)</span>
<span class="sd">        The lowest probability threshold considered</span>
<span class="sd">    step: int [0,vmax-vmin] (default=10)</span>
<span class="sd">        the probability sample rate</span>
<span class="sd">    label: string</span>
<span class="sd">        the name of the classifier considered</span>

<span class="sd">    Yields</span>
<span class="sd">    ------</span>
<span class="sd">    results: DataFrame</span>
<span class="sd">        A dataframe containing the information described above</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># load dataframe cointaing probabilities</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
    <span class="c1"># save number of data on the test set</span>
    <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">vmax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># chose vmax as the minumum between the second highest treshold that returns 0</span>
        <span class="c1"># and the tenth highest threshold that returns 1</span>
        <span class="nb">sorted</span> <span class="o">=</span> <span class="n">prob</span><span class="p">[</span><span class="n">prob</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;first classifier&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">sorted1</span> <span class="o">=</span> <span class="n">prob</span><span class="p">[</span><span class="n">prob</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;first classifier&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">vmax1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">sorted</span><span class="p">[</span><span class="s2">&quot;first classifier&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">vmax2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sorted1</span><span class="p">[</span><span class="s2">&quot;first classifier&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">9</span><span class="p">]</span><span class="o">*</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">vmax</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">vmax1</span><span class="p">,</span> <span class="n">vmax2</span><span class="p">)</span>

        <span class="c1"># delete useless datas</span>
        <span class="k">del</span> <span class="nb">sorted</span><span class="p">,</span> <span class="n">sorted1</span><span class="p">,</span> <span class="n">vmax1</span><span class="p">,</span> <span class="n">vmax2</span>
        <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

    <span class="n">lenght</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">vmax</span><span class="o">-</span><span class="n">vmin</span><span class="p">)</span><span class="o">//</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">acc1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">lenght</span><span class="p">)</span>
    <span class="n">num1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">lenght</span><span class="p">)</span>
    <span class="n">iter1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">lenght</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">thresh</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>

        <span class="n">iter1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">thresh</span><span class="o">/</span><span class="mi">1000</span>
        <span class="c1"># ratio of correctlty classified objects as 1</span>
        <span class="n">yes</span> <span class="o">=</span> <span class="n">prob</span><span class="p">[</span><span class="n">prob</span><span class="p">[</span><span class="s2">&quot;first classifier&quot;</span><span class="p">]</span>
                   <span class="o">&gt;</span> <span class="n">thresh</span><span class="o">/</span><span class="mi">1000</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># ratio of wrongly classified objects as 1</span>
        <span class="n">no</span> <span class="o">=</span> <span class="n">prob</span><span class="p">[</span><span class="n">prob</span><span class="p">[</span><span class="s2">&quot;first classifier&quot;</span><span class="p">]</span>
                  <span class="o">&gt;</span> <span class="n">thresh</span><span class="o">/</span><span class="mi">1000</span><span class="p">][</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># save accuracy on the label 1 and ratio of the objects classified as 1</span>
        <span class="n">acc1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">yes</span><span class="o">/</span><span class="p">(</span><span class="n">yes</span><span class="o">+</span><span class="n">no</span><span class="p">))</span>
        <span class="n">num1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">yes</span><span class="o">+</span><span class="n">no</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">)</span>

        <span class="c1"># next iteration</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span>

    <span class="c1"># create a list containig the name of the classifier</span>
    <span class="n">clf1</span> <span class="o">=</span> <span class="p">[</span><span class="n">label</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">acc1</span><span class="p">]</span>

    <span class="c1"># create a dataframe with all the useful informations</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">acc1</span><span class="p">,</span>
                            <span class="s1">&#39;number of label 1&#39;</span><span class="p">:</span> <span class="n">num1</span><span class="p">,</span>
                            <span class="s1">&#39;classifier&#39;</span><span class="p">:</span> <span class="n">clf1</span><span class="p">,</span>
                            <span class="s1">&#39;iteration&#39;</span><span class="p">:</span> <span class="n">iter1</span><span class="p">,</span>
                            <span class="s1">&#39;func&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">acc1</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">num1</span><span class="p">})</span>

    <span class="k">return</span> <span class="n">results</span></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>

    <span class="n">COMPUTE_PROB</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">COMPUTE_ACC</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">DISTRIBUTION</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="n">COMPUTE_PROB</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>

        <span class="c1"># import dataset</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">import_training_set</span><span class="p">()</span>
        <span class="n">data</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># select best classifier to compare</span>
        <span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
            <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
            <span class="n">bootstrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_samples</span><span class="o">=</span><span class="mf">0.10</span><span class="p">,</span>
            <span class="n">max_features</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.0013</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">bagging_clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">GaussianNB</span><span class="p">(),</span>
                                        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                                        <span class="n">bootstrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                        <span class="n">max_samples</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
                                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                        <span class="n">max_features</span><span class="o">=</span><span class="mf">0.33</span><span class="p">)</span>
        <span class="n">bagging</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
                            <span class="p">(</span><span class="s1">&#39;reduce_dim&#39;</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">30</span><span class="p">)),</span>
                            <span class="p">(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">bagging_clf</span><span class="p">)])</span>
        <span class="n">naive</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
                          <span class="p">(</span><span class="s1">&#39;reduce_dim&#39;</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">30</span><span class="p">)),</span>
                          <span class="p">(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">())])</span>
        <span class="c1"># create list of classifier we want to compare</span>
        <span class="n">classifiers</span> <span class="o">=</span> <span class="p">[</span><span class="n">forest</span><span class="p">,</span> <span class="n">bagging</span><span class="p">,</span> <span class="n">naive</span><span class="p">]</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;forest&quot;</span><span class="p">,</span> <span class="s2">&quot;bag_50&quot;</span><span class="p">,</span> <span class="s2">&quot;naive&quot;</span><span class="p">]</span>
        <span class="c1"># create a copy of the dataset</span>
        <span class="n">new_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># variable used to indicate wich classifier we are considering</span>
        <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># iterate on each classifier</span>
        <span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="n">classifiers</span><span class="p">:</span>
            <span class="c1"># iterate 5 times to make sure we have robust results</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
                <span class="n">max_date</span> <span class="o">=</span> <span class="n">new_data</span><span class="p">[</span><span class="s2">&quot;date&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
                <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">names</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">i</span><span class="p">)</span>
                <span class="c1"># compute the probabilities</span>
                <span class="n">test_size</span> <span class="o">=</span> <span class="n">compute_probabilities</span><span class="p">(</span><span class="n">new_data</span><span class="p">,</span> <span class="n">clf</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
                <span class="c1"># at each iteration reduce the dataset by 25 days</span>
                <span class="n">new_data</span> <span class="o">=</span> <span class="n">new_data</span><span class="p">[</span><span class="n">new_data</span><span class="p">[</span><span class="s2">&quot;date&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">max_date</span><span class="o">-</span><span class="mi">25</span><span class="p">]</span>
            <span class="c1"># increase j to make sure we are testing the next classifier</span>
            <span class="n">j</span> <span class="o">=</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span>
            <span class="c1"># delete new_data since it now has 125 less days than the original dataset</span>
            <span class="k">del</span> <span class="n">max_date</span>
            <span class="k">del</span> <span class="n">new_data</span>
            <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
            <span class="c1"># new_data is now equal to the original dataset</span>
            <span class="n">new_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">COMPUTE_ACC</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>

        <span class="c1"># create a dictionary that will contain the models</span>
        <span class="n">models</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># list containing the names of the models</span>
        <span class="c1"># we will have 5 models because we did a 5 split CV before</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;model_0&quot;</span><span class="p">,</span> <span class="s2">&quot;model_1&quot;</span><span class="p">,</span> <span class="s2">&quot;model_2&quot;</span><span class="p">,</span> <span class="s2">&quot;model_3&quot;</span><span class="p">,</span> <span class="s2">&quot;model_4&quot;</span><span class="p">]</span>
        <span class="c1"># create a dataframe for each forest and then merge them</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">names</span><span class="p">):</span>
            <span class="n">clf_name</span> <span class="o">=</span> <span class="s2">&quot;proba/probabilities_forest_</span><span class="si">{}</span><span class="s2">.csv&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
            <span class="n">models</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">clf_name</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">models</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">])</span>
        <span class="c1"># create a dataframe for each naive bayes and then merge them</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">names</span><span class="p">):</span>
            <span class="n">clf_name</span> <span class="o">=</span> <span class="s2">&quot;proba/probabilities_naive_</span><span class="si">{}</span><span class="s2">.csv&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
            <span class="n">models</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">clf_name</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="n">results1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">models</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">])</span>
        <span class="c1"># create 2 subplots 1 for the random forest and 1 for the naive bayes</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">results</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;iteration&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;func&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">ci</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">results1</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;iteration&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;func&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">ci</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;percentage estimators&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">DISTRIBUTION</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;proba/probabilities_forest_0.csv&quot;</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="s2">&quot;proba/probabilities_forest_0.csv&quot;</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

        <span class="n">mean</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;first classifier&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;first classifier&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>

        <span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">results</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;iteration&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="c1"># g.set_yscale(&#39;log&#39;)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Probability&quot;</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
        <span class="c1"># plt.xscale(&quot;log&quot;)</span>
        <span class="c1"># plt.yscale(&quot;log&quot;)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

        <span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;first classifier&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Bagging and boosting in financial machine learning 1.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">compare_models</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2021, Paolo Spina, Marialaura De Grazia.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.0.1.
    </div>
  </body>
</html>